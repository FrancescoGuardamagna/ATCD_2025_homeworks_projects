{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e950ad66",
   "metadata": {},
   "source": [
    "# **Read the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6f490229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7671,)\n",
      "(7671,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import xarray as xr\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "from shapely.geometry import Polygon, Point\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "input_file_data=\"./ERA_1degree_Daily_2000-2020_allvars2.nc\"\n",
    "input_file_labels=\"./discharge_lobith_daily.xlsx\"\n",
    "\n",
    "def read_data(input_file_data,input_file_labels):\n",
    "    \n",
    "    start_date=datetime(2000,1,1)\n",
    "    end_date=datetime(2021,1,1)\n",
    "    \n",
    "    ds = xr.open_dataset(input_file_data)\n",
    "    labels=pd.read_excel(input_file_labels)\n",
    "    #align labels and input data in the time dimension\n",
    "    labels=labels[np.logical_and(labels['datetime']>=start_date,labels['datetime']<end_date)]\n",
    "    labels=np.array(labels['Q'])\n",
    "    \n",
    "    return ds,labels\n",
    "\n",
    "#load input data and corresponding labels with daily resolution\n",
    "#variable names: tp-> total precipitation t2m-> 2 meters temperature swvl1 -> Volumetric soil water layer 1\n",
    "data,labels=read_data(input_file_data,input_file_labels)\n",
    "\n",
    "#eliminate first longitude which contains nans\n",
    "data=data.sel(latitude=slice(46.0, 53.0), longitude=slice(4, 12))\n",
    "\n",
    "#time_line of the data in datetime format\n",
    "time_line=np.array([datetime.utcfromtimestamp(date.astype('datetime64[s]').astype('int')) for date in np.array(data['time'])])\n",
    "\n",
    "print(time_line.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561e2902",
   "metadata": {},
   "source": [
    "# **Plot January Mean**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bb0ffe5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to select all the samples in January 2020 (for the 3 variables tp,t2m,swl1) given in input \n",
    "#the era5 dataset and the timeline. The function returns the data in numpy format for the 3 variables separately\n",
    "\n",
    "def select_January_data(data,time_line):\n",
    "\n",
    "    #to implement\n",
    "    \n",
    "    return tp_January,t2m_January,swvl1_January\n",
    "\n",
    "#function to plot the Jan 2020 mean given in input the dataset and the time_line\n",
    "def plot_monthly_mean(data,time_line):\n",
    "    \n",
    "    #to implement\n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b005e221",
   "metadata": {},
   "source": [
    "# **Determine Time Delay**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b6a86af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine lagged correlation\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "#function to compute the region average of precipition P and the lagged correlation between the region average \n",
    "#and the corresponding discharge values given in input the ERA5 dataset, the river discharge and the lag. \n",
    "#This function can be used to compute the correlation for different lags to then plot the results\n",
    "def compute_lag_correlation(data,Q,lag):\n",
    "    \n",
    "    #to implement\n",
    "    return lagged_correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a839ea",
   "metadata": {},
   "source": [
    "# **Preprocessing functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d9a9bda4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 54\u001b[0m\n\u001b[1;32m     51\u001b[0m variables\u001b[38;5;241m=\u001b[39m[] \u001b[38;5;66;03m#list of variables names\u001b[39;00m\n\u001b[1;32m     52\u001b[0m X\u001b[38;5;241m=\u001b[39mprepare_data(data,variables)\n\u001b[0;32m---> 54\u001b[0m X_train,X_validation,labels_train,labels_validation,time_line_train,time_line_validation\u001b[38;5;241m=\u001b[39m\u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtime_line\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_train\u001b[38;5;241m.\u001b[39mshape,X_validation\u001b[38;5;241m.\u001b[39mshape,labels_train\u001b[38;5;241m.\u001b[39mshape,labels_validation\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     58\u001b[0m labels_train_scaled,mean_labels,std_labels\u001b[38;5;241m=\u001b[39mnormalize_labels(labels_train,labels_train)\n",
      "Cell \u001b[0;32mIn[49], line 15\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(X, labels, time_line)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_test_split\u001b[39m(X,labels,time_line):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m#to implement\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X_train,X_validation,\u001b[43my_train\u001b[49m,y_validation,time_line_training,time_line_validation\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_train' is not defined"
     ]
    }
   ],
   "source": [
    "#function to select variables from the ERA5 dataset, given in input the dataset and a list containing \n",
    "#variables names, the function return the data in numpy format\n",
    "\n",
    "def prepare_data(data,variables):\n",
    "    #to implement\n",
    "        \n",
    "    return X\n",
    "\n",
    "#function to split data in train/test given in input the data in numpy with corresponding labels and time_line.\n",
    "#Return training set, validation set, training labels, validation labels, training timeline and \n",
    "#validation timeline\n",
    "def train_test_split(X,labels,time_line):\n",
    "    #to implement\n",
    "    \n",
    "    return X_train,X_validation,y_train,y_validation,time_line_training,time_line_validation\n",
    "\n",
    "#function to normalize data based on training data mean and std given in input the dataset we want to use \n",
    "#to compute mean and std (X_mean_std) and the data we want to normalize (X)\n",
    "def normalize_data(X_mean_std,X):\n",
    "    #to implement\n",
    "    \n",
    "    return X_normalized\n",
    "\n",
    "#function to normalize the labels (discharge) based on training data labels, given in input labels to use to \n",
    "#compute mean and std (labels_mean_std) and the labels to normalize (labels).\n",
    "#Return normalized labels and mean and std to reverse normalization\n",
    "def normalize_labels(labels_mean_std,labels):\n",
    "    #to implement\n",
    "    \n",
    "    return labels_normalized,train_mean,train_std\n",
    "    \n",
    "\n",
    "#function to define our samples for training using a rolling time window of dimension t. The dimension of each \n",
    "#sample, must be [t,lat,lon,variables] if you use tensorflow, [variables,t,lat,lon] if you use pytorch.\n",
    "#In input the data we want to transform in mupy format with the corresponding labels and the dimension of \n",
    "#the time window. Return transformed samples and corresponding labels aligned in time with new data\n",
    "def prepare_running_window_samples(X,labels,window_dimension):\n",
    "    #to implement\n",
    "    \n",
    "    return running_dataset,labels_aligned\n",
    "\n",
    "#function to select the winter and summer period data from the validation data, given in input the validation data\n",
    "#in numpy format the validation labels and the validation data time_line. Return the Validation data corresponding\n",
    "#to summer and winter with corresponding labels\n",
    "def select_summer_winter_period(X,labels,time_line):\n",
    "    #to implement\n",
    "    \n",
    "    return X_summer,X_winter,labels_summer,labels_winter\n",
    "        \n",
    "    \n",
    "variables=[] #list of variables names\n",
    "t= #define time window dimension\n",
    "X=prepare_data(data,variables)\n",
    "\n",
    "X_train,X_validation,labels_train,labels_validation,time_line_train,time_line_validation=train_test_split(X,\n",
    "labels,time_line)\n",
    "print(X_train.shape,X_validation.shape,labels_train.shape,labels_validation.shape)\n",
    "\n",
    "labels_train_scaled,mean_labels,std_labels=normalize_labels(labels_train,labels_train)\n",
    "print(labels_train_scaled.shape)\n",
    "\n",
    "X_train_normalized=normalize_data(X_train,X_train)\n",
    "X_validation_normalized=normalize_data(X_train,X_validation)\n",
    "print(X_train_normalized.shape)\n",
    "print(X_validation_normalized.shape)\n",
    "\n",
    "X_train_normalized_sliced,labels_train_sliced=prepare_running_window_samples(X_train_normalized,\n",
    "labels_train_scaled,t)\n",
    "X_validation_normalized_sliced,labels_validation_sliced=prepare_running_window_samples(X_validation_normalized,\n",
    "labels_validation,t)\n",
    "\n",
    "print(X_train_normalized_sliced.shape)\n",
    "print(X_validation_normalized_sliced.shape)\n",
    "print(labels_train_sliced.shape)\n",
    "print(labels_validation_sliced.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfe37bd",
   "metadata": {},
   "source": [
    "# **Definition of Pytorch functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "98f3109d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#define initial hyper-parameters and device gpu. On mac is mps, change it for windows\n",
    "\n",
    "device = torch.device(\"mps\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size=10\n",
    "lr=10**(-4)\n",
    "n_epochs=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8b65935e",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after function definition on line 6 (1617422401.py, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[55], line 11\u001b[0;36m\u001b[0m\n\u001b[0;31m    def __len__(self):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 6\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#define your custom dataset \n",
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, X, labels):\n",
    "\n",
    "    #initialize the dataset with data and corresponding labels\n",
    "    #to implement\n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        #return len of your dataset\n",
    "        #to implement\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        #return the sample in your dataset corresponding to index idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "31cdd519",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after function definition on line 18 (2444845768.py, line 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[56], line 28\u001b[0;36m\u001b[0m\n\u001b[0;31m    def train(data,dataloader,lr,n_epochs):\u001b[0m\n\u001b[0m                                           ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 18\n"
     ]
    }
   ],
   "source": [
    "#define the network\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "#you need to define a network with 2 Conv3d layers, each one with 16 output channels, kernel_size=3 and padding=1.\n",
    "#After each Conv3d layer ReLU activation function. After the 2 Conv3d layer a MaxPool3d layer with kernel size\n",
    "#(2,1,1) and stride (2,1,1) (perform maxpooling only in time direction). After pooling flatten the data then\n",
    "#MLP (Multy layer perceptron) with 3 hidden layers with n_neurons 256, 128 and 64. Relu after each hidden layer.\n",
    "#Output layer with dimension one and linear activation function.\n",
    "\n",
    "class Conv3DNet(nn.Module):\n",
    "    def __init__(self,input_dimensions):\n",
    "        super(Conv3DNet, self).__init__()\n",
    "        \n",
    "        #define the network architecture\n",
    "        #to implement\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #define the forward passage\n",
    "        \n",
    "    \n",
    "#function to train your model. Define the train loop and save after each epoch the mse with respect to normalized\n",
    "#labels and mean absolute error with respect to original labels (reverse transformation). In input \n",
    "#training data in numpy format, training dataloader, learning rate and number of epochs.\n",
    "#Returned trained model, a list containing loss per epoch and a list containing mae per epoch\n",
    "\n",
    "def train(data,dataloader,lr,n_epochs):\n",
    "    #define loss function and optimizer \n",
    "    #to implement\n",
    "    \n",
    "    #define the training loop remember to save loss and mae at each epoch in the correct way\n",
    "    for epoch in range(n_epochs):\n",
    "        #to implement\n",
    "\n",
    "        for i, data in enumerate(dataloader):\n",
    "            # Iterate over the batches and save loss and mae to then compute loss and mae per epoch\n",
    "            #to implement\n",
    "    \n",
    "    return model,loss_epochs,mae_epochs\n",
    "    \n",
    "#convert training data to tensors\n",
    "X_train_torch=torch.from_numpy(X_train_normalized_sliced).float()\n",
    "labels_train_torch=torch.from_numpy(labels_train_sliced).float()\n",
    "\n",
    "#define custom dataset using training data\n",
    "dataset=CustomDataset(X_train_torch,labels_train_torch)\n",
    "#define dataloader using the custom dataset\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size,\n",
    "                        shuffle=False)\n",
    "\n",
    "model,loss_epochs,mae_epochs=train(X_train_torch,dataloader,lr,n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "47936a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert validation data to tensors\n",
    "X_validation_torch=torch.from_numpy(X_validation_normalized_sliced).float()\n",
    "labels_validation_torch=torch.from_numpy(labels_validation_sliced).float()\n",
    "#define validation custom dataset\n",
    "dataset=CustomDataset(X_validation_torch,labels_validation_torch)\n",
    "#define validation dataloader\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size,shuffle=False)\n",
    "\n",
    "#this function return predictions and real labels given in input the trained model and a dataloader \n",
    "#containing the test data with corresponding labels\n",
    "\n",
    "def predict(model,dataloader):\n",
    "    \n",
    "    #to implement\n",
    "    \n",
    "    return predictions, true_labels\n",
    "\n",
    "predictions,true_labels=predict(model,dataloader)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0179c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
